---
title: "Sample training polygons"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir=normalizePath("../.."))
```

Load libraries and scripts
```{r}
library(sf)
library(tidyverse)
library("")
```

# Sample polygons used to extract pixels for training

Using labelme, polygons were drawn over ~50 ground-based photographs of regions within a coastal dune system (SHNA) consisting of a variety of ground cover classes (ex sand, vegetation)

These polygons were manually labeled so a training, validation, and testing set could be generated to classify pixels
at a pixel level using supervised machine learning.


```{r}
sample_polygons <- function(quadrat) {
  directories <- sprintf("clean_data/quadrats/quadrat%02d/rgb.json", seq(34, 83, 1))
  quadrats[[directory]] %>%
    label_me_json_to_sf() %>%
    dplyr::mutate(quadrat = directory, area = st_area(.$polys)) %>%
    dplyr::mutate(label = case_when(label == "live Marram grass" ~ "live vegetation", TRUE ~ label)) %>%
    filter(is.element(label, c("live vegetation", "dead vegetation", "sand"))) %>%
    mutate(poly_num = c(1:length(polys)))
}


polys_sf <- seq(1, 50) %>%
  map(sample_polygons)

(polys_sf %>% st_make_valid() %>% count(label) -> label_counts)

```